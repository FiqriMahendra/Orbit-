{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Titanic challenge part 1\nIn this notebook, we will be covering all of the steps required to wrangle the Titanic data set into a format that is suitable for machine learning.   \nWe will do each of the following:\n  - impute missing values\n  - create new features (feature engineering)\n  \n[**Part 2**](https://www.kaggle.com/jamesleslie/titanic-random-forest-grid-search) of this challenge involves fitting and tuning a **random forest** to make predictions.","metadata":{"_uuid":"9b3e43f6f3787243de855b9416a0b5697be6d116"}},{"cell_type":"markdown","source":"# Table of Contents:\n\n- **1. [Load Packages and Data](#loading)**\n- **2. [Imputation](#impute-missing)**\n  - **2.1. [Age](#age)**\n  - **2.1. [Fare](#fare)**\n  - **2.1. [Embarked](#embarked)**\n- **3. [Feature engineering](#feature-engineering)**","metadata":{"_uuid":"cc4b58927770beab136969e526dbbd69a9cc21c8","_cell_guid":"969e5a36-8f64-4129-ba03-7fd19b314ca9"}},{"cell_type":"markdown","source":"<a id=\"loading\"></a>\n# 1. Load packages and data\nFirst step, as always, is to import the necessary Python packages and load the input data as a Pandas dataframe.\n\nI chose to combine the train and test set into one. Since we will have to impute some missing age and fare values, I prefer to do this across the entire dataset, rather than separately across train and test sets. ","metadata":{"_uuid":"de8369a5716eb80519979ef773ecbb135f66e4b9","_cell_guid":"ec3a4ceb-2397-45b3-aafe-a8ffde879888"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import rcParams\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\n%matplotlib inline\nrcParams['figure.figsize'] = 10,8\nsns.set(style='whitegrid', palette='muted',\n        rc={'figure.figsize': (12,8)})\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# print(os.listdir(\"../input\"))","metadata":{"_kg_hide-output":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-10-02T20:59:50.003601Z","iopub.execute_input":"2021-10-02T20:59:50.003965Z","iopub.status.idle":"2021-10-02T20:59:51.29718Z","shell.execute_reply.started":"2021-10-02T20:59:50.003901Z","shell.execute_reply":"2021-10-02T20:59:51.296173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data as Pandas dataframe\ntrain = pd.read_csv('../input/train.csv', )\ntest = pd.read_csv('../input/test.csv')\ndf = pd.concat([train, test], axis=0, sort=True)","metadata":{"_kg_hide-output":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-10-02T20:59:51.298533Z","iopub.execute_input":"2021-10-02T20:59:51.298774Z","iopub.status.idle":"2021-10-02T20:59:51.345856Z","shell.execute_reply.started":"2021-10-02T20:59:51.298723Z","shell.execute_reply":"2021-10-02T20:59:51.344704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"_uuid":"bafdb419c8b7f571dbbb9c0b63fd3c52c66c3c1b","execution":{"iopub.status.busy":"2021-10-02T20:59:51.347149Z","iopub.execute_input":"2021-10-02T20:59:51.347411Z","iopub.status.idle":"2021-10-02T20:59:51.389478Z","shell.execute_reply.started":"2021-10-02T20:59:51.34736Z","shell.execute_reply":"2021-10-02T20:59:51.388526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)\n\n        \ndisplay_all(df.describe(include='all').T)","metadata":{"_uuid":"d8f24917231bd2484e4c2a4896f4fbbdcc3e89ab","execution":{"iopub.status.busy":"2021-10-02T20:59:51.390693Z","iopub.execute_input":"2021-10-02T20:59:51.390984Z","iopub.status.idle":"2021-10-02T20:59:51.452854Z","shell.execute_reply.started":"2021-10-02T20:59:51.390933Z","shell.execute_reply":"2021-10-02T20:59:51.451788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Survived'].value_counts()","metadata":{"_uuid":"ca279aca8e6064618de4b7badb8d94366628cf2b","execution":{"iopub.status.busy":"2021-10-02T20:59:51.457586Z","iopub.execute_input":"2021-10-02T20:59:51.458017Z","iopub.status.idle":"2021-10-02T20:59:51.467973Z","shell.execute_reply.started":"2021-10-02T20:59:51.457945Z","shell.execute_reply":"2021-10-02T20:59:51.46717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"impute-missing\"></a>\n# 2. Imputation \nWe can see above that there are a few columns with missing values. The `Cabin` column is missing over 1000 values, so we won't use that for predictions, but the `Age`, `Embarked` and `Fare` columns are all complete enough that we can fill in the missing values through imputation.   \n<a id=\"age\"></a>\n## 2.1. Impute missing age values\nA simple option for the missing age values is to use the median age value. Let's go a little further and use each passenger's *Title* to estimate their age. E.g. if a passenger has the title of *Dr*, I will give them the median age value for all other passengers with the same title.","metadata":{"_uuid":"6152dbc2be0eb940262b335a13c8e781dcaf9547","_cell_guid":"384a2527-3f03-4ba7-b921-80cdd8d97467"}},{"cell_type":"markdown","source":"### Extract title from name\nWe can use a regular expression to extract the title from the `Name` column. We will do this by finding the adjacent letters that are immediately followed by a full stop.\n","metadata":{"_uuid":"a3f1ad45c884fdbfeaaa57394232d86dbb0dc045"}},{"cell_type":"code","source":"# create new Title column\ndf['Title'] = df['Name'].str.extract('([A-Za-z]+)\\.', expand=True)","metadata":{"_uuid":"ce8dbcdef57c823e0a8fc84fe258e3d6d2878eb0","execution":{"iopub.status.busy":"2021-10-02T20:59:51.469503Z","iopub.execute_input":"2021-10-02T20:59:51.469771Z","iopub.status.idle":"2021-10-02T20:59:51.483191Z","shell.execute_reply.started":"2021-10-02T20:59:51.469721Z","shell.execute_reply":"2021-10-02T20:59:51.48223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"scrolled":true,"_uuid":"4cb27d2ab1cbc07fbc1ad3feaeb3b1a33b861e34","execution":{"iopub.status.busy":"2021-10-02T20:59:51.484521Z","iopub.execute_input":"2021-10-02T20:59:51.484887Z","iopub.status.idle":"2021-10-02T20:59:51.526847Z","shell.execute_reply.started":"2021-10-02T20:59:51.484831Z","shell.execute_reply":"2021-10-02T20:59:51.526134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use only the most common titles\nLet's take a look at the unique titles across all passengers:","metadata":{"_uuid":"e8e4a264de33ed63dca5c242dff80166e8af0e19"}},{"cell_type":"code","source":"df['Title'].value_counts()","metadata":{"_uuid":"66022b3cf723a4f302e7cedc47d416d5acb13956","execution":{"iopub.status.busy":"2021-10-02T20:59:51.527783Z","iopub.execute_input":"2021-10-02T20:59:51.528065Z","iopub.status.idle":"2021-10-02T20:59:51.541746Z","shell.execute_reply.started":"2021-10-02T20:59:51.528025Z","shell.execute_reply":"2021-10-02T20:59:51.540785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see above, there are quite a few different titles. However, many of these titles are just French versions of the more common English titles, e.g. Mme = Madame = Mrs.   \n\nWe will use the six most common titles, replacing all other titles with the most appropriate of these six.","metadata":{"_uuid":"7c7edd6ec1cea98a3897a610b53bb8e596bc1fc4"}},{"cell_type":"code","source":"# replace rare titles with more common ones\nmapping = {'Mlle': 'Miss', 'Major': 'Mr', 'Col': 'Mr', 'Sir': 'Mr',\n           'Don': 'Mr', 'Mme': 'Mrs', 'Jonkheer': 'Mr', 'Lady': 'Mrs',\n           'Capt': 'Mr', 'Countess': 'Mrs', 'Ms': 'Miss', 'Dona': 'Mrs'}\ndf.replace({'Title': mapping}, inplace=True)","metadata":{"_uuid":"82f29d6a36b898b116844a983c9fb3f97afd40b4","_cell_guid":"682eafff-b707-4dc8-bd25-dcf309394a22","execution":{"iopub.status.busy":"2021-10-02T20:59:51.54302Z","iopub.execute_input":"2021-10-02T20:59:51.54339Z","iopub.status.idle":"2021-10-02T20:59:51.557485Z","shell.execute_reply.started":"2021-10-02T20:59:51.543252Z","shell.execute_reply":"2021-10-02T20:59:51.556219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# confirm that we are left with just six values\ndf['Title'].value_counts()","metadata":{"scrolled":true,"_uuid":"a7a8abaf9ebc744c96cc2aba4dbbd067f0a0ea39","execution":{"iopub.status.busy":"2021-10-02T20:59:51.55876Z","iopub.execute_input":"2021-10-02T20:59:51.559058Z","iopub.status.idle":"2021-10-02T20:59:51.567236Z","shell.execute_reply.started":"2021-10-02T20:59:51.559007Z","shell.execute_reply":"2021-10-02T20:59:51.566192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Use median of title group\nNow, for each missing age value, we will impute the age using the median age for all people with the same title.","metadata":{"_uuid":"5a68c0c5b9b4ef37e611968042bfcb5a9dcfd4b1"}},{"cell_type":"code","source":"# impute missing Age values using median of Title groups\ntitle_ages = dict(df.groupby('Title')['Age'].median())\n\n# create a column of the average ages\ndf['age_med'] = df['Title'].apply(lambda x: title_ages[x])\n\n# replace all missing ages with the value in this column\ndf['Age'].fillna(df['age_med'], inplace=True, )\ndel df['age_med']","metadata":{"_uuid":"82f29d6a36b898b116844a983c9fb3f97afd40b4","_cell_guid":"682eafff-b707-4dc8-bd25-dcf309394a22","execution":{"iopub.status.busy":"2021-10-02T20:59:51.568491Z","iopub.execute_input":"2021-10-02T20:59:51.568749Z","iopub.status.idle":"2021-10-02T20:59:51.582394Z","shell.execute_reply.started":"2021-10-02T20:59:51.5687Z","shell.execute_reply":"2021-10-02T20:59:51.581452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can visualize the median ages for each title group. Below, we see that each title has a distinctly different median age. \n> **Note**: There is no risk in doing this after imputation, as the median of an age group has not been affected by our actions.","metadata":{"_uuid":"7020e115b0bf1ede99f832d6bd4ba81946afdb2e","_cell_guid":"e533812d-5343-43b3-9a0b-d766aee9d25a"}},{"cell_type":"code","source":"sns.barplot(x='Title', y='Age', data=df, estimator=np.median, ci=None, palette='Blues_d')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"_kg_hide-output":false,"_cell_guid":"ba23acb8-6953-4be9-805a-5aa9ff58afa7","_uuid":"8a937faf6acac597c89b9a53879c0a28e7f3e6ea","execution":{"iopub.status.busy":"2021-10-02T20:59:51.583454Z","iopub.execute_input":"2021-10-02T20:59:51.583689Z","iopub.status.idle":"2021-10-02T20:59:51.848418Z","shell.execute_reply.started":"2021-10-02T20:59:51.583654Z","shell.execute_reply":"2021-10-02T20:59:51.847341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='Title', data=df, palette='hls', hue='Survived')\nplt.xticks(rotation=45)\nplt.show()","metadata":{"_uuid":"3c11a0c2eb46ff9e9001fe745e52d4e45af887a7","_cell_guid":"e67c4523-dc07-4864-9c21-8eada3afaa66","execution":{"iopub.status.busy":"2021-10-02T20:59:51.85019Z","iopub.execute_input":"2021-10-02T20:59:51.850712Z","iopub.status.idle":"2021-10-02T20:59:52.120128Z","shell.execute_reply.started":"2021-10-02T20:59:51.850583Z","shell.execute_reply":"2021-10-02T20:59:52.119146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"fare\"></a>\n## 2.2. Impute missing fare values\nFor the single missing fare value, I also use the median fare value for the passenger's class.   \n\n> Perhaps you could come up with a cooler way of visualising the relationship between the price a passenger paid for their ticket and their chances of survival?","metadata":{"_uuid":"576a68ad24bdd1f95042dec25e29ee9477249473","_cell_guid":"06ef5753-c5a2-4513-a66a-2ab583b14744"}},{"cell_type":"code","source":"sns.swarmplot(x='Sex', y='Fare', hue='Survived', data=df)\nplt.show()","metadata":{"_uuid":"ae237610d1830732dc68edaa13cbba3f6f36f401","execution":{"iopub.status.busy":"2021-10-02T20:59:52.121556Z","iopub.execute_input":"2021-10-02T20:59:52.122065Z","iopub.status.idle":"2021-10-02T20:59:57.731692Z","shell.execute_reply.started":"2021-10-02T20:59:52.121999Z","shell.execute_reply":"2021-10-02T20:59:57.730431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# impute missing Fare values using median of Pclass groups\nclass_fares = dict(df.groupby('Pclass')['Fare'].median())\n\n# create a column of the average fares\ndf['fare_med'] = df['Pclass'].apply(lambda x: class_fares[x])\n\n# replace all missing fares with the value in this column\ndf['Fare'].fillna(df['fare_med'], inplace=True, )\ndel df['fare_med']","metadata":{"_uuid":"945f58a6cbc7c60b4a2e3d7792380971868cd62b","execution":{"iopub.status.busy":"2021-10-02T20:59:57.733436Z","iopub.execute_input":"2021-10-02T20:59:57.734074Z","iopub.status.idle":"2021-10-02T20:59:57.750426Z","shell.execute_reply.started":"2021-10-02T20:59:57.734011Z","shell.execute_reply":"2021-10-02T20:59:57.748994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"embarked\"></a>\n## 2.3. Impute missing \"embarked\" value\nThere are also just two missing values in the `Embarked` column. Here we will just use the Pandas 'backfill' method.\n","metadata":{"_uuid":"03eff72da37a32621f586fa05ec9bd43a86b94cc"}},{"cell_type":"code","source":"sns.catplot(x='Embarked', y='Survived', data=df,\n            kind='bar', palette='muted', ci=None)\nplt.show()","metadata":{"_uuid":"bcac215b7a3d62878cf2ae9bbbd147a3c68d6ef1","execution":{"iopub.status.busy":"2021-10-02T20:59:57.7526Z","iopub.execute_input":"2021-10-02T20:59:57.753458Z","iopub.status.idle":"2021-10-02T20:59:57.98326Z","shell.execute_reply.started":"2021-10-02T20:59:57.752981Z","shell.execute_reply":"2021-10-02T20:59:57.981777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Embarked'].fillna(method='backfill', inplace=True)","metadata":{"_uuid":"53f0275ecb0d7539e20348b6b5714ab9b545cb44","execution":{"iopub.status.busy":"2021-10-02T20:59:57.985117Z","iopub.execute_input":"2021-10-02T20:59:57.985723Z","iopub.status.idle":"2021-10-02T20:59:57.992104Z","shell.execute_reply.started":"2021-10-02T20:59:57.985438Z","shell.execute_reply":"2021-10-02T20:59:57.991113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"feature-engineering\"></a>\n# 3. Add family size column\nWe can use the two variables of **Parch** and **SibSp** to create a new variable called **Family_Size**. This is simply done by adding `Parch` and `SibSp` together.","metadata":{"_uuid":"1c6849d36813451fd544b05bdf4b7d071c83b319","_cell_guid":"547fff99-bfed-4dbc-a36e-10df63924257"}},{"cell_type":"code","source":"# create Family_Size column (Parch +)\ndf['Family_Size'] = df['Parch'] + df['SibSp']","metadata":{"_uuid":"df1bc9d1e0531d81063dee472a4fe403f37a15c0","_cell_guid":"ba8193da-2ab7-4551-ba77-8d23fa045408","execution":{"iopub.status.busy":"2021-10-02T20:59:57.993534Z","iopub.execute_input":"2021-10-02T20:59:57.994084Z","iopub.status.idle":"2021-10-02T20:59:58.11622Z","shell.execute_reply.started":"2021-10-02T20:59:57.994025Z","shell.execute_reply":"2021-10-02T20:59:58.115463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_all(df.describe(include='all').T)","metadata":{"_uuid":"77030dd6593199746e33baf4c8668751782c805e","execution":{"iopub.status.busy":"2021-10-02T20:59:58.117771Z","iopub.execute_input":"2021-10-02T20:59:58.118126Z","iopub.status.idle":"2021-10-02T20:59:58.182189Z","shell.execute_reply.started":"2021-10-02T20:59:58.118054Z","shell.execute_reply":"2021-10-02T20:59:58.181257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Save cleaned version\nFinally, let's save our cleaned data set so we can use it in other notebooks.","metadata":{"_uuid":"ad262cbf41b929d0ad560e6984cb9aaec06ce58e"}},{"cell_type":"code","source":"train = df[pd.notnull(df['Survived'])]\ntest = df[pd.isnull(df['Survived'])]","metadata":{"_uuid":"515a01dc5a736a1170c923bab565d77900db7039","execution":{"iopub.status.busy":"2021-10-02T20:59:58.183538Z","iopub.execute_input":"2021-10-02T20:59:58.184065Z","iopub.status.idle":"2021-10-02T20:59:58.191024Z","shell.execute_reply.started":"2021-10-02T20:59:58.184006Z","shell.execute_reply":"2021-10-02T20:59:58.190316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.to_csv('train_clean.csv', index=False)\ntest.to_csv('test_clean.csv', index=False)","metadata":{"_uuid":"089e09c1640ff4e914be335eecf706b1e6c08800","execution":{"iopub.status.busy":"2021-10-02T20:59:58.192191Z","iopub.execute_input":"2021-10-02T20:59:58.192613Z","iopub.status.idle":"2021-10-02T20:59:58.443753Z","shell.execute_reply.started":"2021-10-02T20:59:58.192563Z","shell.execute_reply":"2021-10-02T20:59:58.442903Z"},"trusted":true},"execution_count":null,"outputs":[]}]}